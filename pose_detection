import cv2
import json
import time
import random
from ultralytics import YOLO
import paho.mqtt.client as mqtt

# MQTT Configurations
MQTT_BROKER = "10.0.0.25" #"10.243.82.33" 
STATUS_TOPIC = "bot/state"
SENSORS_TOPIC = "bot/sensors"
CONTROL_TOPIC = "bot/motors"

# Initialize MQTT Client
client = mqtt.Client()

# Global variables for the PD controller
Kp = 0.1  # Proportional gain
Kd = 0.05  # Derivative gain
SAFE_ZONE_RADIUS = 5  # Safe zone radius around the target center, in pixels
STOP_DISTANCE_THRESHOLD = 50  # Distance threshold for stopping, in cm

# Initialize variables
current_model = None
current_model_name = ""
vid = cv2.VideoCapture(0)
previous_error = 0

# Dictionary of detectable objects, reversed for name-to-ID mapping
object_classes = {
    'person': 0, 'bicycle': 1, 'car': 2, 'motorcycle': 3, 'airplane': 4, 'bus': 5, 'train': 6, 'truck': 7,
    'boat': 8, 'traffic light': 9, 'fire hydrant': 10, 'stop sign': 11, 'parking meter': 12, 'bench': 13,
    'bird': 14, 'cat': 15, 'dog': 16, 'horse': 17, 'sheep': 18, 'cow': 19, 'elephant': 20, 'bear': 21,
    'zebra': 22, 'giraffe': 23, 'backpack': 24, 'umbrella': 25, 'handbag': 26, 'tie': 27, 'suitcase': 28,
    'frisbee': 29, 'skis': 30, 'snowboard': 31, 'sports ball': 32, 'kite': 33, 'baseball bat': 34,
    'baseball glove': 35, 'skateboard': 36, 'surfboard': 37, 'tennis racket': 38, 'bottle': 39, 'wine glass': 40,
    'cup': 41, 'fork': 42, 'knife': 43, 'spoon': 44, 'bowl': 45, 'banana': 46, 'apple': 47, 'sandwich': 48,
    'orange': 49, 'broccoli': 50, 'carrot': 51, 'hot dog': 52, 'pizza': 53, 'donut': 54, 'cake': 55,
    'chair': 56, 'couch': 57, 'potted plant': 58, 'bed': 59, 'dining table': 60, 'toilet': 61, 'tv': 62,
    'laptop': 63, 'mouse': 64, 'remote': 65, 'keyboard': 66, 'cell phone': 67, 'microwave': 68, 'oven': 69,
    'toaster': 70, 'sink': 71, 'refrigerator': 72, 'book': 73, 'clock': 74, 'vase': 75, 'scissors': 76,
    'teddy bear': 77, 'hair drier': 78, 'toothbrush': 79
}

PERSON_ID = object_classes['person']
second_object_name = 'bottle'
second_object_id = object_classes.get(second_object_name)

# Motor Control Class
class MotorControl:
    def __init__(self, mqtt_client, control_topic):
        self.client = mqtt_client
        self.control_topic = control_topic

    def _publish_command(self, pwm_values):
        payload = json.dumps({"pwm": pwm_values})
        self.client.publish(self.control_topic, payload)
        print(f"Published motor command: {payload}")

    def spin(self, dir="left", speed=100):
        left_pwm = -speed if dir == "left" else speed
        right_pwm = speed if dir == "left" else -speed
        self._publish_command([left_pwm, right_pwm])

    def stop(self):
        self._publish_command([0, 0])

    def move(self, left_pwm, right_pwm):
        self._publish_command([left_pwm, right_pwm])

motors = MotorControl(client, CONTROL_TOPIC)

# Load model function
def load_model(model_name):
    global current_model, current_model_name
    if current_model_name == model_name:
        print(f"Model '{model_name}' is already loaded.")
        return
    model_path = f"yolo_models/{model_name}.pt"
    current_model = YOLO(model_path, verbose=False)
    current_model_name = model_name
    print(f"Model '{model_name}' loaded successfully.")

# Process detection frame
def process_detection_frame(frame):
    global current_model
    target_width, target_height = 640, int(640 * frame.shape[0] / frame.shape[1])
    resized_frame = cv2.resize(frame, (target_width, target_height))
    resized_frame = cv2.flip(resized_frame, 1)

    results = current_model(resized_frame, conf=0.6, verbose=False)
    filtered_boxes = [box for box in results[0].boxes if box.cls in [PERSON_ID, second_object_id]]
    results[0].boxes = filtered_boxes
    annotated_frame = results[0].plot()
    return annotated_frame

# Process pose frame
def process_pose_frame(frame):
    global current_model
    target_width, target_height = 640, int(640 * frame.shape[0] / frame.shape[1])
    resized_frame = cv2.resize(frame, (target_width, target_height))
    resized_frame = cv2.flip(resized_frame, 1)

    results = current_model(resized_frame, conf=0.6, verbose=False)
    annotated_frame = results[0].plot()
    return annotated_frame

# Annotate FPS and size
def annotate_fps_and_size(frame, start_time):
    fps = 1 / (time.time() - start_time)
    cv2.putText(frame, f"Size: {frame.shape[1]}x{frame.shape[0]}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
    cv2.putText(frame, f"FPS: {int(fps)}", (frame.shape[1] - 150, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
    return frame

# State Functions
def state_boot_up():
    print("Boot-up: Initializing system and checking connections.")

def state_await_activation():
    print("Awaiting activation: Monitoring IMU for device tap.")

def state_detect_pickup_location():
    print("Detecting pickup location: Scanning for person and object.")
    load_model('yolo11s')
    motors.spin(dir="left", speed=100)

def state_retrieval():
    print("Retrieval: Navigating to target using PD control.")
    load_model('yolo11s')
    navigate_to_target()

def state_procurement():
    print("Procurement: Awaiting package placement.")
    motors.stop()

def state_detect_delivery_location():
    print("Detecting delivery location: Scanning for delivery point.")
    load_model('yolo11s-pose')
    motors.spin(dir="right", speed=100)

def state_shipping():
    print("Shipping: Navigating to delivery point.")
    load_model('yolo11s-pose')
    navigate_to_target()

def state_delivery():
    print("Delivery: Awaiting package removal.")
    motors.stop()

# Dictionary to map state IDs to functions
state_functions = {
    0: state_boot_up,
    1: state_await_activation,
    2: state_detect_pickup_location,
    3: state_retrieval,
    4: state_procurement,
    5: state_detect_delivery_location,
    6: state_shipping,
    7: state_delivery,
}

# Handle state by looking up the function in the dictionary
def handle_state(payload):
    state = payload.get("state", None)
    if state is not None and state in state_functions:
        print(f"Received state: {state}")
        state_functions[state]()

# Navigate to target with PD control
def navigate_to_target():
    global previous_error
    print("Navigating to target...")

    while True:
        ret, frame = vid.read()
        if not ret:
            print("Failed to capture frame.")
            continue

        results = current_model(frame, conf=0.6, verbose=False)
        
        target_found = False
        for box in results[0].boxes:
            if box.cls == PERSON_ID or box.cls == second_object_id:
                x_min, y_min, x_max, y_max = map(int, box.xyxy[0])
                target_center_x = (x_min + x_max) // 2
                frame_center_x = frame.shape[1] // 2
                error = target_center_x - frame_center_x
                target_found = True
                break

        if target_found:
            if abs(error) <= SAFE_ZONE_RADIUS:
                left_pwm = right_pwm = 150
            else:
                error_derivative = error - previous_error
                control_signal = Kp * error + Kd * error_derivative
                previous_error = error
                base_speed = 150
                left_pwm = base_speed + control_signal
                right_pwm = base_speed - control_signal
            
            left_pwm = max(min(int(left_pwm), 255), -255)
            right_pwm = max(min(int(right_pwm), 255), -255)
            motors.move(left_pwm, right_pwm)
        
        else:
            motors.stop()
            print("Target lost.")
            break

        lidar_distance = get_lidar_distance()
        if lidar_distance <= STOP_DISTANCE_THRESHOLD:
            motors.stop()
            print("Reached target.")
            break

        time.sleep(0.1)

# Simulated LIDAR distance reading
def get_lidar_distance():
    return random.randint(30, 100)

# MQTT Callbacks
def on_connect(client, userdata, flags, rc):
    print("Connected to MQTT broker with result code " + str(rc))
    client.subscribe([(STATUS_TOPIC, 0), (SENSORS_TOPIC, 0)])

def on_message(client, userdata, msg):
    payload = json.loads(msg.payload.decode())
    if msg.topic == STATUS_TOPIC:
        handle_state(payload)
    elif msg.topic == SENSORS_TOPIC:
        handle_sensor_data(payload)

def handle_sensor_data(payload):
    imu_data = payload.get("imu", {})
    lidar_data = payload.get("lidar", None)
    print(f"Received IMU data: {imu_data}, LiDAR distance: {lidar_data}")

# Initialize MQTT client and set callbacks
client.on_connect = on_connect
client.on_message = on_message
client.connect(MQTT_BROKER)
client.loop_start()

# Main loop
try:
    load_model('yolo11s')  # Default model at start

    while True:
        start_time = time.time()
        ret, frame = vid.read()
        if not ret:
            break

        # Process the frame based on the current model
        if current_model_name == 'yolo11s':
            annotated_frame = process_detection_frame(frame)
        elif current_model_name == 'yolo11s-pose':
            annotated_frame = process_pose_frame(frame)
        
        # Annotate FPS and size
        annotated_frame = annotate_fps_and_size(annotated_frame, start_time)

        # Display the frame
        cv2.namedWindow("Annotated Feed", cv2.WINDOW_NORMAL)
        cv2.setWindowProperty("Annotated Feed", cv2.WND_PROP_TOPMOST, 1)
        cv2.imshow("Annotated Feed", annotated_frame)

        # Exit on 'q'
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

except KeyboardInterrupt:
    print("Process interrupted.")
finally:
    client.loop_stop()
    vid.release()
    cv2.destroyAllWindows()
